{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Projet 3 — Prédiction de prix de l'immobilier avec modèles classiques**\n",
        "\n",
        "Objectif : Prédire les prix des maisons selon caractéristiques + zone géographique\n",
        "\n",
        "Techniques : Feature Engineering, Random Forest, Gradient Boosting\n",
        "\n",
        "Dataset : House Prices - Advanced Regression\n",
        "\n",
        "Tâches :\n",
        "\n",
        "•\tEncodage, imputation\n",
        "\n",
        "•\tPipeline de transformation\n",
        "\n",
        "•\tComparaison de modèles\n",
        "\n",
        "•\tFeature importance\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AvPFWj5YXA7f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un **pipeline** est une chaîne d’étapes de traitement des données et de modélisation, regroupées dans un seul objet.\n",
        "Cela permet de préparer automatiquement les données et d’entraîner le modèle sans faire chaque étape à la main .\n",
        "\n",
        "par exemple : Pipeline(\n",
        "\n",
        "  steps=[\n",
        "    \n",
        "   ('imputer', SimpleImputer(strategy='median')),   # remplir les valeurs manquantes\n",
        "\n",
        "  ('scaler', StandardScaler()),                    # normaliser les données\n",
        "\n",
        "  ('model', RandomForestRegressor())              # entraîner le modèle\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "q1vvWoAcp6ow"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_Lts5ATjW1y7"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, StackingRegressor\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(y_true, y_pred):\n",
        " return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "\n",
        "def log_transform(y):   #Les prix des maisons ont souvent une distribution très asymétrique ,Faire un log réduit l’influence des très grandes valeurs\n",
        " return np.log1p(y)\n",
        "\n",
        "\n",
        "def inv_log_transform(y): #Quand on prédit avec un modèle entraîné sur les valeurs log-transformées, il faut revenir aux valeurs originales.\n",
        " return np.expm1(y)"
      ],
      "metadata": {
        "id": "5OE9W0r4qjTo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/drive/MyDrive/ai/dane/train.csv'\n",
        "test_path = '/content/drive/MyDrive/ai/dane/test.csv'\n",
        "\n",
        "\n",
        "if not os.path.exists(train_path) or not os.path.exists(test_path):\n",
        " raise FileNotFoundError(\"train.csv and test.csv must be present in the working directory.\")\n",
        "\n",
        "\n",
        "train = pd.read_csv(train_path)\n",
        "test = pd.read_csv(test_path)\n",
        "\n",
        "\n",
        "test_ids = test['Id']"
      ],
      "metadata": {
        "id": "RAj5YYZgWzkV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_engineering(df):\n",
        "  df = df.copy()\n",
        "\n",
        "\n",
        "  # Age of the house\n",
        "  df['HouseAge'] = df['YrSold'] - df['YearBuilt']\n",
        "  df['RemodAge'] = df['YrSold'] - df['YearRemodAdd']\n",
        "\n",
        "\n",
        "  # Total area\n",
        "  df['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF']\n",
        "  df['TotalPorchSF'] = df['OpenPorchSF'] + df['EnclosedPorch'] + df['3SsnPorch'] + df['ScreenPorch']\n",
        "\n",
        "\n",
        "  # Simplify some quality/condition scores (convert to numeric)\n",
        "  qual_dict = {\n",
        "  'Ex': 5, 'Gd': 4, 'TA': 3, 'Fa': 2, 'Po': 1\n",
        "  }\n",
        "  for col in ['ExterQual', 'ExterCond', 'HeatingQC', 'KitchenQual', 'FireplaceQu', 'GarageQual']:\n",
        "    if col in df.columns:\n",
        "      df[col] = df[col].map(qual_dict)\n",
        "\n",
        "\n",
        "  # Bathrooms total\n",
        "  df['TotalBath'] = df['FullBath'] + 0.5 * df['HalfBath'] + df['BsmtFullBath'] + 0.5 * df['BsmtHalfBath']\n",
        "\n",
        "\n",
        "  # Simplify overall quality*condition\n",
        "  if 'OverallQual' in df.columns and 'OverallCond' in df.columns:\n",
        "    df['OverallScore'] = df['OverallQual'] * df['OverallCond']\n",
        "\n",
        "\n",
        "  # Neighborhood average prices (for train only, safe encoding)\n",
        "  if 'SalePrice' in df.columns:\n",
        "    df['Neighborhood_MeanPrice'] = df.groupby('Neighborhood')['SalePrice'].transform('mean')\n",
        "  else:\n",
        "    df['Neighborhood_MeanPrice'] = np.nan # will be imputed later\n",
        "\n",
        "\n",
        "  return df\n",
        "\n",
        "\n",
        "# Apply feature engineering\n",
        "train = feature_engineering(train)\n",
        "test = feature_engineering(test)"
      ],
      "metadata": {
        "id": "yGH8PLAzW7IR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.drop(columns=['Id'])\n",
        "y = train['SalePrice']\n",
        "X = train.drop(columns=['SalePrice'])\n",
        "\n",
        "\n",
        "numeric_feats = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "cat_feats = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "\n",
        "print(f'Numeric features: {len(numeric_feats)}, Categorical features: {len(cat_feats)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dA7vfFSXHTk",
        "outputId": "f556c6ae-fa88-46f3-de64-2819028da5d0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numeric features: 49, Categorical features: 37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "numeric_pipeline = Pipeline([\n",
        "('imputer', SimpleImputer(strategy='median')),\n",
        "('scaler', StandardScaler()),\n",
        "])\n",
        "\n",
        "\n",
        "categorical_pipeline = Pipeline([\n",
        "('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False)),\n",
        "])\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "('num', numeric_pipeline, numeric_feats),\n",
        "('cat', categorical_pipeline, cat_feats),\n",
        "])\n",
        "\n",
        "\n",
        "y_trans = log_transform(y)"
      ],
      "metadata": {
        "id": "qxlD5KsDXSVy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y_trans, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "QV7bHArtXTvP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
        "rf_pipeline = Pipeline([\n",
        "('pre', preprocessor),\n",
        "('rf', rf)\n",
        "])\n",
        "gbr = GradientBoostingRegressor(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "gbr_pipeline = Pipeline([\n",
        "('pre', preprocessor),\n",
        "('gbr', gbr)\n",
        "])\n",
        "\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "print('\\nBaseline cross-val RMSE (log target)')\n",
        "for name, pipe in [('RandomForest', rf_pipeline), ('GradientBoosting', gbr_pipeline)]:\n",
        "  scores = cross_val_score(pipe, X, y_trans, scoring='neg_mean_squared_error', cv=kf, n_jobs=-1)\n",
        "  rmses = np.sqrt(-scores)\n",
        "  print(f'{name}: mean RMSE = {rmses.mean():.4f}, std = {rmses.std():.4f}')\n",
        "\n",
        "\n",
        "rf_param_grid = {\n",
        "'rf__n_estimators': [200, 400],\n",
        "'rf__max_depth': [10, 20, None],\n",
        "'rf__min_samples_split': [2, 5]\n",
        "}\n",
        "\n",
        "\n",
        "gbr_param_grid = {\n",
        "'gbr__n_estimators': [200, 400],\n",
        "'gbr__learning_rate': [0.05, 0.1],\n",
        "'gbr__max_depth': [3, 5]\n",
        "}\n",
        "\n",
        "\n",
        "print('\\nRunning GridSearch on RandomForest')\n",
        "rf_search = GridSearchCV(rf_pipeline, rf_param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
        "rf_search.fit(X_train, y_train)\n",
        "print('RF best params:', rf_search.best_params_)\n",
        "\n",
        "\n",
        "print('\\nRunning GridSearch on GradientBoosting')\n",
        "gbr_search = GridSearchCV(gbr_pipeline, gbr_param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=1)\n",
        "gbr_search.fit(X_train, y_train)\n",
        "print('GBR best params:', gbr_search.best_params_)\n",
        "\n",
        "\n",
        "rf_best = rf_search.best_estimator_\n",
        "gbr_best = gbr_search.best_estimator_\n",
        "\n",
        "\n",
        "rf_pred_log = rf_best.predict(X_valid)\n",
        "gbr_pred_log = gbr_best.predict(X_valid)\n",
        "\n",
        "\n",
        "print('\\nValidation RMSE (log target):')\n",
        "print('RF:', rmse(y_valid, rf_pred_log))\n",
        "print('GBR:', rmse(y_valid, gbr_pred_log))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDPMfyneXZP5",
        "outputId": "9a6012f1-61ca-4c83-b777-245c4d41c371"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Baseline cross-val RMSE (log target)\n",
            "RandomForest: mean RMSE = 0.1393, std = 0.0184\n",
            "GradientBoosting: mean RMSE = 0.1299, std = 0.0152\n",
            "\n",
            "Running GridSearch on RandomForest\n",
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "RF best params: {'rf__max_depth': 20, 'rf__min_samples_split': 2, 'rf__n_estimators': 400}\n",
            "\n",
            "Running GridSearch on GradientBoosting\n",
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "GBR best params: {'gbr__learning_rate': 0.05, 'gbr__max_depth': 3, 'gbr__n_estimators': 400}\n",
            "\n",
            "Validation RMSE (log target):\n",
            "RF: 0.14147320108207873\n",
            "GBR: 0.1321363389319283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor.fit(X_train)\n",
        "num_names = numeric_feats\n",
        "cat_ohe = preprocessor.named_transformers_['cat'].named_steps['onehot']\n",
        "cat_names = cat_ohe.get_feature_names_out(cat_feats).tolist()\n",
        "all_feature_names = num_names + cat_names\n",
        "\n",
        "\n",
        "rf_model = rf_best.named_steps['rf']\n",
        "rf_importances = rf_model.feature_importances_\n",
        "feat_imp = pd.Series(rf_importances, index=all_feature_names).sort_values(ascending=False)\n",
        "print('\\nTop 30 feature importances (Random Forest)')\n",
        "print(feat_imp.head(30))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XTiJGrTXkyh",
        "outputId": "4edf238d-b064-4efb-cfac-b00f4a44ea02"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 30 feature importances (Random Forest)\n",
            "OverallQual               0.366555\n",
            "TotalSF                   0.357776\n",
            "Neighborhood_MeanPrice    0.061588\n",
            "OverallScore              0.025318\n",
            "GrLivArea                 0.012905\n",
            "GarageArea                0.011790\n",
            "LotArea                   0.009444\n",
            "TotalBath                 0.009373\n",
            "BsmtFinSF1                0.007998\n",
            "BsmtUnfSF                 0.006631\n",
            "HouseAge                  0.006340\n",
            "RemodAge                  0.005830\n",
            "GarageCars                0.005682\n",
            "YearBuilt                 0.005249\n",
            "1stFlrSF                  0.005187\n",
            "TotalBsmtSF               0.004774\n",
            "YearRemodAdd              0.004299\n",
            "CentralAir_Y              0.004107\n",
            "KitchenQual               0.003825\n",
            "2ndFlrSF                  0.003806\n",
            "LotFrontage               0.003769\n",
            "CentralAir_N              0.003415\n",
            "TotalPorchSF              0.003391\n",
            "GarageYrBlt               0.003101\n",
            "OverallCond               0.003010\n",
            "OpenPorchSF               0.002907\n",
            "MoSold                    0.002875\n",
            "GarageType_Detchd         0.002507\n",
            "Fireplaces                0.002501\n",
            "BsmtQual_Ex               0.002151\n",
            "dtype: float64\n"
          ]
        }
      ]
    }
  ]
}